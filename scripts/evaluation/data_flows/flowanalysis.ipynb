{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e107ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Set\n",
    "import os\n",
    "import xmltodict\n",
    "from xml.etree.ElementTree import Element, tostring, parse\n",
    "from xml.parsers.expat import ExpatError\n",
    "from run.icc_connection import parse_iotscope, ValuePoint, get_value_point, create_key_map\n",
    "import json\n",
    "import run.icc_connection\n",
    "#import importlib\n",
    "#import parse_ip\n",
    "#importlib.reload(parse_ip)\n",
    "from parse_ip import parse_ip_or_domain, parse_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cea246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatementLocation:\n",
    "    def __init__(self, statement, parent_method, line_number):\n",
    "        self.statement = statement\n",
    "        self.parent_method = parent_method\n",
    "        self.line_number = line_number\n",
    "        self.value_scope_results = []\n",
    "\n",
    "    def set_source_values(self, value_scope_results: List[ValuePoint]):\n",
    "        self.value_scope_results = value_scope_results\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"ICC(stmt: {self.statement}, parent_method: {self.parent_method}, line_number {self.line_number})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.parent_method, self.line_number))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return (self.parent_method, self.line_number) == (other.parent_method, other.line_number)\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        # Not strictly necessary, but to avoid having both x==y and x!=y\n",
    "        # True at the same time\n",
    "        return not (self == other)\n",
    "\n",
    "\n",
    "class FlowDroidResult:\n",
    "    def __init__(self, sink: StatementLocation, sources: List[StatementLocation]):\n",
    "        self.sink = sink\n",
    "        self.sources = sources\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.sink, self.sources))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return (self.sink, self.sources) == (other.sink, other.sources)\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        # Not strictly necessary, but to avoid having both x==y and x!=y\n",
    "        # True at the same time\n",
    "        return not (self == other)\n",
    "\n",
    "\n",
    "class AppResult:\n",
    "    def __init__(self, flows: List[FlowDroidResult], call_graph_construction_seconds, taint_propagation_seconds,\n",
    "                 path_reconstruction_seconds, total_runtime, max_memory_consumption, path: Optional[str]):\n",
    "        self.flows = flows\n",
    "        self.call_graph_construction_seconds = call_graph_construction_seconds\n",
    "        self.taint_propagation_seconds = taint_propagation_seconds\n",
    "        self.path_reconstruction_seconds = path_reconstruction_seconds\n",
    "        self.total_runtime = total_runtime\n",
    "        self.max_memory_consumption = max_memory_consumption\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "class FlowDroidRun:\n",
    "    def __init__(self, to_icc_or_sink: AppResult, from_icc_to_sink: AppResult, app_id: str, sources: List[ValuePoint],\n",
    "                 sinks: List[ValuePoint], both: Optional[List[AppResult]] = None,\n",
    "                 source_connections: Optional[List[AppResult]] = None,\n",
    "                 sink_connections: Optional[List[AppResult]] = None, iot_scope_results: List[ValuePoint] = None):\n",
    "        self.to_icc_or_sink = to_icc_or_sink\n",
    "        self.from_icc_to_sink = from_icc_to_sink\n",
    "        self.sources = sources\n",
    "        self.sinks = sinks\n",
    "        self.app_id = app_id\n",
    "        self.both = both\n",
    "        self.source_connections = source_connections\n",
    "        self.sink_connections = sink_connections\n",
    "        self.iot_scope_results = iot_scope_results\n",
    "\n",
    "\n",
    "class PotentialLeak:\n",
    "\n",
    "    def __init__(self, sources: List[StatementLocation], icc_sink: Optional[StatementLocation],\n",
    "                 icc_source: Optional[List[StatementLocation]], sink: StatementLocation):\n",
    "        self.sources = sources\n",
    "        self.icc_sink = icc_sink\n",
    "        self.icc_source = icc_source\n",
    "        self.sink = sink\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Flow(stmt: {self.sources}, parent_method: {self.icc_sink}, keys {self.icc_source}, line_number {self.sink})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class AnalyzedApp:\n",
    "    def __init__(self, app_data: FlowDroidRun, potentialLeaks: List[PotentialLeak]):\n",
    "        self.source_connections = {}\n",
    "        self.sink_connections = {}\n",
    "        self.app_data = app_data\n",
    "        self.potentialLeaks = potentialLeaks\n",
    "\n",
    "    def get_values(self, stmt: StatementLocation):\n",
    "        keys: Set = set()\n",
    "        for vp in self.app_data.iot_scope_results:\n",
    "            if (vp.parent_method == stmt.parent_method) and (int(vp.line_number) == int(stmt.line_number)):\n",
    "                keys.update(vp.keys)\n",
    "\n",
    "        return keys\n",
    "\n",
    "    def add_source_values(self, sources: List[StatementLocation]) -> List[StatementLocation]:\n",
    "        result = []\n",
    "        for source in sources:\n",
    "            keys = self.get_values(source)\n",
    "            source.set_source_values(keys)\n",
    "            result.append(source)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def set_sink_connection(self, leak: PotentialLeak, sources: List[StatementLocation]):\n",
    "        tmp = self.sink_connections.get(leak, [])\n",
    "        tmp.extend(self.add_source_values(sources))\n",
    "        self.sink_connections[leak] = tmp\n",
    "\n",
    "    def set_source_connection(self, leak: PotentialLeak, sources: List[StatementLocation]):\n",
    "        tmp = self.source_connections.get(leak, [])\n",
    "        tmp.extend(self.add_source_values(sources))\n",
    "        self.source_connections[leak] = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d093fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement_location(flowdroid_statement):\n",
    "    statement = flowdroid_statement.get(\"@Statement\", \"<>\")\n",
    "    statement = statement[statement.index(\"<\"): statement.index(\">\") + 1]\n",
    "    parent_method = flowdroid_statement.get(\"@Method\", \"\")\n",
    "    line_number = flowdroid_statement.get(\"@LineNumber\", -1)\n",
    "    return StatementLocation(statement, parent_method, line_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_flowdroid(path) -> AppResult:\n",
    "    flows = []\n",
    "    iotflow_result = None\n",
    "    # load stmt if key is not available look at the icc\n",
    "    try:\n",
    "        with open(path, \"r\") as xml_obj:\n",
    "            # coverting the xml data to Python dictionary\n",
    "            iotflow_result = xmltodict.parse(xml_obj.read())\n",
    "            # closing the file\n",
    "            xml_obj.close()\n",
    "        if iotflow_result is not None:\n",
    "            # print(json.dumps(iotflow_result))\n",
    "            flow_result = iotflow_result.get(\"DataFlowResults\", {})\n",
    "            results = flow_result.get(\"Results\", {})\n",
    "            all_results = results.get(\"Result\", [])\n",
    "            if type(all_results) is not type([]):\n",
    "                all_results = [all_results]\n",
    "            for result in all_results:\n",
    "                sink = result.get(\"Sink\", {})\n",
    "                sources = result.get(\"Sources\", {})\n",
    "                current_sink = get_value_point(sink)\n",
    "                all_sources = sources.get(\"Source\", [])\n",
    "                current_sources = []\n",
    "\n",
    "                if type(all_sources) is not type([]):\n",
    "                    all_sources = [all_sources]\n",
    "                for source in all_sources:\n",
    "                    current_source = get_value_point(source)\n",
    "                    current_sources.append(current_source)\n",
    "\n",
    "                flows.append(FlowDroidResult(current_sink, current_sources))\n",
    "\n",
    "        cgc = None\n",
    "        tp = None\n",
    "        pr = None\n",
    "        tr = None\n",
    "        mm = None\n",
    "        # data_flow_result = xml_data.find(\"DataFlowResults\")\n",
    "        xml_data: Element = parse(path).getroot()\n",
    "\n",
    "        performance_data = xml_data.find(\"PerformanceData\")\n",
    "        if performance_data is not None:\n",
    "            for performance_entry in performance_data.findall(\"PerformanceEntry\"):\n",
    "                if performance_entry.get(\"Name\") == \"CallgraphConstructionSeconds\":\n",
    "                    cgc = (int(performance_entry.get(\"Value\")))\n",
    "                elif performance_entry.get(\"Name\") == \"TaintPropagationSeconds\":\n",
    "                    tp = (int(performance_entry.get(\"Value\")))\n",
    "                elif performance_entry.get(\"Name\") == \"PathReconstructionSeconds\":\n",
    "                    pr = (int(performance_entry.get(\"Value\")))\n",
    "                elif performance_entry.get(\"Name\") == \"TotalRuntimeSeconds\":\n",
    "                    tr = (int(performance_entry.get(\"Value\")))\n",
    "                elif performance_entry.get(\"Name\") == \"MaxMemoryConsumption\":\n",
    "                    mm = (int(performance_entry.get(\"Value\")))\n",
    "\n",
    "        return AppResult(flows, cgc, tp, pr, tr, mm, path)\n",
    "\n",
    "    except ExpatError as e:\n",
    "        print(path)\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_from_folder(path, extension, filename):\n",
    "    result = []\n",
    "    folder_name = os.path.join(path, extension)\n",
    "    for folder in os.listdir(folder_name):\n",
    "        try:\n",
    "            result.append(parse_flowdroid(os.path.join(os.path.join(folder_name, folder), filename)))\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_all_IoT_scope_results(path: str, json_file_name: str):\n",
    "    result: List[ValuePoint] = []\n",
    "    try:\n",
    "        tmp = parse_iotscope(os.path.join(os.path.join(path, \"amqp\"), json_file_name))\n",
    "        result.extend(tmp)\n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        tmp = parse_iotscope(os.path.join(os.path.join(path, \"coap\"), json_file_name))\n",
    "        result.extend(tmp)\n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        tmp = parse_iotscope(os.path.join(os.path.join(path, \"endpoints\"), json_file_name))\n",
    "        result.extend(tmp)\n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        tmp = parse_iotscope(os.path.join(os.path.join(path, \"mqtt\"), json_file_name))\n",
    "        result.extend(tmp)\n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        tmp = parse_iotscope(os.path.join(os.path.join(path, \"udp\"), json_file_name))\n",
    "        result.extend(tmp)\n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "    try:\n",
    "        tmp = parse_iotscope(os.path.join(os.path.join(path, \"webview\"), json_file_name))\n",
    "        result.extend(tmp)\n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        tmp = parse_iotscope(os.path.join(os.path.join(path, \"xmpp\"), json_file_name))\n",
    "        result.extend(tmp)\n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_dataset(path: str, prefix) -> List[FlowDroidRun]:\n",
    "    #both\n",
    "    #sink_connection\n",
    "    #source_connection\n",
    "    result = []\n",
    "    for f in os.listdir(os.path.join(path, f\"{prefix}_to_icc_or_sink\")):\n",
    "        try:\n",
    "            to_icc = parse_flowdroid(os.path.join(os.path.join(path, f\"{prefix}_to_icc_or_sink\"), f))\n",
    "        except FileNotFoundError as e:\n",
    "            #print(e)\n",
    "            to_icc = None\n",
    "\n",
    "        try:\n",
    "            from_icc = parse_flowdroid(os.path.join(os.path.join(path, f\"{prefix}_from_icc_to_sink\"), f))\n",
    "        except FileNotFoundError as e:\n",
    "            #print(e)\n",
    "            from_icc = None\n",
    "\n",
    "        try:\n",
    "            sources = parse_iotscope(os.path.join(os.path.join(path, \"sources\"), f.replace(\".xml\", \".json\")))\n",
    "        except FileNotFoundError as e:\n",
    "            #print(e)\n",
    "            sources = None\n",
    "\n",
    "        try:\n",
    "            sinks = parse_iotscope(os.path.join(os.path.join(path, \"sinks\"), f.replace(\".xml\", \".json\")))\n",
    "        except FileNotFoundError as e:\n",
    "            #print(e)\n",
    "            sinks = None\n",
    "\n",
    "        both = get_all_from_folder(path, \"both\", f)\n",
    "        source_connections = get_all_from_folder(path, \"source_connection\", f)\n",
    "        sink_connections = get_all_from_folder(path, \"sink_connection\", f)\n",
    "\n",
    "        app_name = f[0:len(f) - len(\".xml\")]\n",
    "        result.append(\n",
    "            FlowDroidRun(to_icc, from_icc, app_name, sources, sinks, both, source_connections, sink_connections,\n",
    "                         parse_all_IoT_scope_results(path, f.replace(\".xml\", \".json\"))))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_local_dataset(path: str) -> List[FlowDroidRun]:\n",
    "    return parse_dataset(path, \"local\")\n",
    "\n",
    "\n",
    "def parse_bl_dataset(path: str) -> List[FlowDroidRun]:\n",
    "    return parse_dataset(path, \"bl\")\n",
    "\n",
    "\n",
    "def parse_general_dataset(path: str) -> List[FlowDroidRun]:\n",
    "    return parse_dataset(path, \"general\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_icc_sinks(path_bl_run_config):\n",
    "    sinks = set()\n",
    "    xml_template: Element = parse(path_bl_run_config).getroot()\n",
    "    category = xml_template.findall(\"category\")\n",
    "    for category in category:\n",
    "        for method in category.findall(\"method\"):\n",
    "            method_signature = method.get(\"signature\")\n",
    "            params = method.findall(\"param\") + method.findall(\"base\") + method.findall(\"return\")\n",
    "            #print(len(params))\n",
    "            for param in params:\n",
    "                access_path = param.find(\"accessPath\")\n",
    "\n",
    "                if access_path.get(\"isSink\") == \"true\":\n",
    "                    if method_signature.startswith(\"android.content.Intent:\") or method_signature.startswith(\n",
    "                            \"android.content.SharedPreferences$Editor:\") or method_signature.startswith(\n",
    "                        \"android.os.Bundle:\"):\n",
    "                        sinks.add(method_signature)\n",
    "\n",
    "    return sinks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_apps(dataset: List[FlowDroidRun], name, mapping) -> List[FlowDroidRun]:\n",
    "    result = []\n",
    "    for app in dataset:\n",
    "        app_name = app.app_id\n",
    "        if app_name in mapping:\n",
    "            if mapping[app_name] == name:\n",
    "                result.append(app)\n",
    "        else:\n",
    "            result.append(app)\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_verified_dataset(base_path, mapping_file, prefix):\n",
    "    mapping_json = {}\n",
    "    with open(mapping_file, \"r\") as f:\n",
    "        mapping_json = json.load(f)\n",
    "\n",
    "    neupane = parse_dataset(os.path.join(base_path, \"neupane\"), prefix)\n",
    "    neupane = filter_apps(neupane, \"neupane\", mapping_json, )\n",
    "\n",
    "    iotspotter = parse_dataset(os.path.join(base_path, \"iotspotter\"), prefix)\n",
    "    iotspotter = filter_apps(iotspotter, \"iotspotter\", mapping_json)\n",
    "\n",
    "    iotprofiler = parse_dataset(os.path.join(base_path, \"iotprofiler\"), prefix)\n",
    "    iotprofiler = filter_apps(iotprofiler, \"iotprofiler\", mapping_json)\n",
    "\n",
    "    return neupane + iotprofiler + iotspotter\n",
    "\n",
    "\n",
    "def parse_verified_dataset_local(path: str, mapping_file) -> List[FlowDroidRun]:\n",
    "    return parse_verified_dataset(path, mapping_file, \"local\")\n",
    "\n",
    "\n",
    "def parse_verified_dataset_bl(path: str, mapping_file) -> List[FlowDroidRun]:\n",
    "    return parse_verified_dataset(path, mapping_file, \"bl\")\n",
    "\n",
    "\n",
    "def parse_verified_dataset_general(path: str, mapping_file) -> List[FlowDroidRun]:\n",
    "    return parse_verified_dataset(path, mapping_file, \"general\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc50377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a695ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(access_path.get(\"isSource\"))\n",
    "#print(element.get(\"signature\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db811d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d834f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_method(signature: str):\n",
    "    signature = signature.strip()\n",
    "    signature_splitted = signature.split(\" \")\n",
    "    if len(signature_splitted) >= 2:\n",
    "        result = signature_splitted[2]\n",
    "        if result.endswith(\">\"):\n",
    "            result = result[0: len(result) - 1]\n",
    "        return result\n",
    "\n",
    "    return signature\n",
    "\n",
    "\n",
    "def get_only_method_list(signature_list: List[str]):\n",
    "    result = []\n",
    "    for signature in signature_list:\n",
    "        result.append(get_method(signature))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sink_keys(sinks: List[ValuePoint], stmt: StatementLocation):\n",
    "    result = []\n",
    "    if sinks is not None and stmt is not None:\n",
    "        for sink in sinks:\n",
    "            if sink.parent_method == stmt.parent_method and int(sink.line_number) == int(stmt.line_number):\n",
    "                return sink.keys\n",
    "    #print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfcf614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1b563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f792c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_already_contain_flow(result: List[FlowDroidResult], flow: FlowDroidResult):\n",
    "    if flow in result:\n",
    "        #print(\"old flow\")\n",
    "        return True\n",
    "\n",
    "    #print(\"new flow\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_matching_flows_from_icc(potential_sources: List[ValuePoint], icc_to_sink_run: AppResult):\n",
    "    result = []\n",
    "    if icc_to_sink_run is not None and icc_to_sink_run.flows is not None:\n",
    "        for flow in icc_to_sink_run.flows:\n",
    "            if flow.sources is not None:\n",
    "                for source in flow.sources:\n",
    "                    for ps in potential_sources:\n",
    "                        if source.parent_method == ps.parent_method and int(ps.line_number) == int(source.line_number):\n",
    "                            if not does_already_contain_flow(result, flow):\n",
    "                                result.append(flow)\n",
    "\n",
    "                    #print(type(potential_sources[0]))\n",
    "                    #if ValuePoint(source.stmt,source.parent_method,None, source.line_number) in potential_sources:\n",
    "                    #    print(\"match\")\n",
    "                    #    result.append(flow)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_matching_flows(app_result: FlowDroidRun, icc_sinks) -> List[PotentialLeak]:\n",
    "    result_list: List[PotentialLeak] = []\n",
    "    if app_result.to_icc_or_sink is None or app_result.to_icc_or_sink.flows is None:\n",
    "        return result_list\n",
    "\n",
    "    source_map = {}\n",
    "    if app_result.sources is not None:\n",
    "        source_map = create_key_map(app_result.sources)\n",
    "\n",
    "    for result in app_result.to_icc_or_sink.flows:\n",
    "        if get_method(result.sink.stmt) in icc_sinks:\n",
    "            #print(app_result.sources)\n",
    "            keys = get_sink_keys(app_result.sinks, result.sink)\n",
    "            #import time\n",
    "            #time.sleep(0.01)\n",
    "            #print(\"---------\")\n",
    "            #print(keys)\n",
    "            #print(source_map)\n",
    "            #print(\"---------\")\n",
    "\n",
    "            # get stmt and  match connection\n",
    "            for key in keys:\n",
    "                #print(key)\n",
    "                if key in source_map:\n",
    "                    #print(key)\n",
    "                    flows = get_matching_flows_from_icc(source_map[key], app_result.from_icc_to_sink)\n",
    "                    for flow in flows:\n",
    "                        result_list.append(PotentialLeak(result.sources, result.sink, flow.sources, flow.sink))\n",
    "                        #print(\"match\")\n",
    "\n",
    "        else:\n",
    "            result_list.append(PotentialLeak(result.sources, None, None, result.sink))\n",
    "            # found a flow\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c386ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_dataset(dataset) -> List[AnalyzedApp]:\n",
    "    leaks: List[AnalyzedApp] = []\n",
    "    for app in dataset:\n",
    "        leaks.append(AnalyzedApp(app, get_matching_flows(app, icc_sinks_methods)))\n",
    "    return leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6c64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b23c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_java_methods(results: List[AnalyzedApp]) -> List[AnalyzedApp]:\n",
    "    keywords_of_false_positives = [\"ArchiveInputStream\", \"FileOutputStream\", \"Zip\", \"Disk\", \"bluetooth\", \"Bluetooth\",\n",
    "                                   \"java.util.zip\", \"zip.DeflaterOutputStream\", \"java.io.FileWriter\", \"writeToFile\",\n",
    "                                   \"saveTxtFile\", \"writetoSDCard\"]\n",
    "    filtered_results: List[AnalyzedApp] = []\n",
    "    for app in results:\n",
    "        current_result: List[PotentialLeak] = []\n",
    "        for app_result in app.potentialLeaks:\n",
    "            contains_keyword = False\n",
    "            if not app_result.sink.stmt.replace(\"<\", \"\").startswith(\"java.io\"):\n",
    "                current_result.append(app_result)\n",
    "                continue\n",
    "            for keyword in keywords_of_false_positives:\n",
    "                #print(type(app_result.sink))\n",
    "                if keyword in app_result.sink.parent_method or keyword in app_result.sink.stmt:\n",
    "                    contains_keyword = True\n",
    "\n",
    "            if not contains_keyword:\n",
    "                current_result.append(app_result)\n",
    "        filtered_results.append(AnalyzedApp(app, current_result))\n",
    "    return filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe140f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8047f4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b08073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sink_connection(analyzedApp: AnalyzedApp):\n",
    "    flows = []\n",
    "    if analyzedApp.app_data.both != None and analyzedApp.app_data.sink_connections:\n",
    "        flows = analyzedApp.app_data.both + analyzedApp.app_data.sink_connections\n",
    "    elif analyzedApp.app_data.both != None:\n",
    "        flows = analyzedApp.app_data.both\n",
    "    elif analyzedApp.app_data.sink_connections:\n",
    "        flows = analyzedApp.app_data.sink_connections\n",
    "    for run in flows:\n",
    "        if run is None:\n",
    "            continue\n",
    "        for flow in run.flows:\n",
    "            for leak in analyzedApp.potentialLeaks:\n",
    "                if int(leak.sink.line_number) == int(\n",
    "                        flow.sink.line_number) and leak.sink.parent_method == flow.sink.parent_method:\n",
    "                    analyzedApp.set_sink_connection(leak, flow.sources)\n",
    "\n",
    "    return analyzedApp\n",
    "\n",
    "\n",
    "def get_source_connection(analyzedApp: AnalyzedApp):\n",
    "    flows = []\n",
    "    if analyzedApp.app_data.both != None and analyzedApp.app_data.source_connections:\n",
    "        flows = analyzedApp.app_data.both + analyzedApp.app_data.source_connections\n",
    "    elif analyzedApp.app_data.both != None:\n",
    "        flows = analyzedApp.app_data.both\n",
    "    elif analyzedApp.app_data.source_connections:\n",
    "        flows = analyzedApp.app_data.source_connections\n",
    "\n",
    "    for run in flows:\n",
    "        if run is None:\n",
    "            continue\n",
    "        for flow in run.flows:\n",
    "            for leak in analyzedApp.potentialLeaks:\n",
    "                for source in leak.sources:\n",
    "                    if int(source.line_number) == int(\n",
    "                            flow.sink.line_number) and source.parent_method == flow.sink.parent_method:\n",
    "                        analyzedApp.set_source_connection(leak, flow.sources)\n",
    "\n",
    "    return analyzedApp\n",
    "\n",
    "\n",
    "def get_all_source_sink_connection(dataset: List[AnalyzedApp]) -> List[AnalyzedApp]:\n",
    "    result: List[AnalyzedApp] = []\n",
    "    for app in dataset:\n",
    "        current = get_sink_connection(app)\n",
    "        current = get_source_connection(current)\n",
    "        result.append(current)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_java_sinks(dataset: List[AnalyzedApp]) -> List[AnalyzedApp]:\n",
    "    result = []\n",
    "    for app in dataset:\n",
    "        app_leaks = []\n",
    "        for leak in app.potentialLeaks:\n",
    "            if leak.sink.stmt.replace(\"<\", \"\").startswith(\"java.io\"):\n",
    "                if leak in app.sink_connections:\n",
    "                    #print(app.sink_connections[leak])\n",
    "                    app_leaks.append(leak)\n",
    "            else:\n",
    "                app_leaks.append(leak)\n",
    "\n",
    "        app.potentialLeaks = app_leaks\n",
    "        result.append(app)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_filter_datset(dataset: List[FlowDroidRun]):\n",
    "    analyzed = analyze_dataset(dataset)\n",
    "\n",
    "    analyzed = get_all_source_sink_connection(analyzed)\n",
    "    return filter_java_sinks(analyzed)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "multicast_addresses = ['255.255.255.255', '224.0.0.', '224.0.1.', '224.0.2.', '224.1.', '224.3.', '224.4.', '225.',\n",
    "                       '226.',\n",
    "                       '227.', '228.', '229.', '230.', '231.', '232.', '233.', '234.', '235.', '236.', '237.',\n",
    "                       '238.', '239.',\n",
    "                       'ffx0:', 'ffx1:', 'ffx2:', 'ffx3:', 'ffx4:', 'ffx5:', 'ffx6:', 'ffx7:', 'ffx8:', 'ffx9:',\n",
    "                       'ffxa:',\n",
    "                       'ffxb:', 'ffxc:', 'ffxd:', 'ffxe:', 'ff02:', 'ff0x:']\n",
    "\n",
    "\n",
    "def is_local_value(address: str) -> bool:\n",
    "    local_network = re.findall(\n",
    "        \"(192\\.168\\.\\d\\d?\\d?\\.\\d\\d?\\d?)|(10\\.\\d\\d?\\d?\\.\\d\\d?\\d?\\.\\d\\d?\\d?)|(172\\.1[6-9]\\.\\d\\d?\\d?\\.\\d\\d?\\d?)|(172\\.2[0-9]\\.\\d\\d?\\d?\\.\\d\\d?\\d?)|(172\\.3[0-1]\\.\\d\\d?\\d?\\.\\d\\d?\\d?)|(.*[^:]fromui\\.local[:\\/ ])|(fd00:)|(fe80:)|(fc00:)\",\n",
    "        address)\n",
    "    if len(local_network) > 0:\n",
    "        return True\n",
    "\n",
    "    for ma in multicast_addresses:\n",
    "        if address.startswith(ma):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_local_value(addresses: Set[str]) -> bool:\n",
    "    for address in addresses:\n",
    "        if is_local_value(address):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_no_local_value(addresses: Set[str]) -> bool:\n",
    "    for address in addresses:\n",
    "        if not is_local_value(address):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_local_dataset(dataset: List[AnalyzedApp], local_to_remote: bool = False):\n",
    "    result: List[FlowDroidRun] = []\n",
    "    for app in dataset:\n",
    "        current_flows = []\n",
    "\n",
    "        for flow in app.potentialLeaks:\n",
    "            current_source_values = set()\n",
    "            current_sink_values = set()\n",
    "\n",
    "            if flow in app.source_connections:\n",
    "                for sc in app.source_connections[flow]:\n",
    "                    sc: StatementLocation = sc\n",
    "                    current_source_values.update(sc.value_scope_results)\n",
    "\n",
    "            if flow in app.sink_connections:\n",
    "                for sc in app.sink_connections[flow]:\n",
    "                    sc: StatementLocation = sc\n",
    "                    current_sink_values.update(sc.value_scope_results)\n",
    "\n",
    "            current_source_values = parse_all(current_source_values)\n",
    "            current_sink_values = parse_all(current_sink_values)\n",
    "\n",
    "            if has_local_value(current_source_values):\n",
    "                if local_to_remote:\n",
    "                    if has_no_local_value(current_sink_values):\n",
    "                        current_flows.append(flow)\n",
    "                else:\n",
    "                    current_flows.append(flow)\n",
    "\n",
    "        tmp = AnalyzedApp(app.app_data, current_flows)\n",
    "        tmp.source_connections = app.source_connections\n",
    "        tmp.sink_connections = app.sink_connections\n",
    "        result.append(tmp)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_stats_general(dataset: List[AnalyzedApp]):\n",
    "    count_flows = 0\n",
    "    count_apps = 0\n",
    "    flows_via_icc = {}\n",
    "    general_count_map = {}\n",
    "    general_app_map = {}\n",
    "\n",
    "    for app in dataset:\n",
    "        sources_in_app = set()\n",
    "        for leak in app.potentialLeaks:\n",
    "            for source in leak.sources:\n",
    "                general_count_map[source.stmt] = general_count_map.get(source.stmt, 0) + 1\n",
    "                sources_in_app.add(source.stmt)\n",
    "                if leak.icc_sink is not None:\n",
    "                    flows_via_icc[source.stmt] = flows_via_icc.get(source.stmt, 0) + 1\n",
    "\n",
    "        for source in sources_in_app:\n",
    "            general_app_map[source] = general_app_map.get(source, 0) + 1\n",
    "\n",
    "    return general_count_map, general_app_map, flows_via_icc\n",
    "\n",
    "\n",
    "def get_stats(dataset: List[AnalyzedApp]):\n",
    "    count_flows = 0\n",
    "    count_apps = 0\n",
    "    flows_via_icc = 0\n",
    "    flows_with_sink_values = 0\n",
    "    apps_with_sink_values = 0\n",
    "\n",
    "    for app in dataset:\n",
    "        if len(app.potentialLeaks) > 0:\n",
    "            count_flows = count_flows + len(app.potentialLeaks)\n",
    "            count_apps = count_apps + 1\n",
    "            has_sink_value = False\n",
    "            for leak in app.potentialLeaks:\n",
    "                current_sink_values = set()\n",
    "                if leak.icc_source is not None and leak.icc_sink is not None:\n",
    "                    flows_via_icc = flows_via_icc + 1\n",
    "\n",
    "                if leak in app.sink_connections:\n",
    "                    for sc in app.sink_connections[leak]:\n",
    "                        sc: StatementLocation = sc\n",
    "                        current_sink_values.update(sc.value_scope_results)\n",
    "\n",
    "                if len(current_sink_values) > 0:\n",
    "                    flows_with_sink_values = flows_with_sink_values + 1\n",
    "                    has_sink_value = True\n",
    "\n",
    "            if has_sink_value:\n",
    "                apps_with_sink_values = apps_with_sink_values + 1\n",
    "\n",
    "    return count_flows, count_apps, flows_via_icc, flows_with_sink_values, apps_with_sink_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_flows_with_source_sink_connection(dataset: List[AnalyzedApp], only_if_sink_values:bool = False) -> str:\n",
    "    result = \"\"\n",
    "    for app in dataset:\n",
    "\n",
    "        for flow in app.potentialLeaks:\n",
    "            current_source_values = set()\n",
    "            current_sink_values = set()\n",
    "\n",
    "            if flow in app.source_connections:\n",
    "                for sc in app.source_connections[flow]:\n",
    "                    sc: StatementLocation = sc\n",
    "                    current_source_values.update(sc.value_scope_results)\n",
    "\n",
    "            if flow in app.sink_connections:\n",
    "                for sc in app.sink_connections[flow]:\n",
    "                    sc: StatementLocation = sc\n",
    "                    current_sink_values.update(sc.value_scope_results)\n",
    "\n",
    "            if only_if_sink_values and len(parse_all(current_sink_values)) == 0 :\n",
    "                continue\n",
    "            result += \"--------------------------------------------------------------\\n\"\n",
    "            if app.app_data is not None:\n",
    "                result += (app.app_data.app_id + \"\\n\")\n",
    "            if len(current_source_values) > 0:\n",
    "                result += f\"We reconstructed for the source connection: {parse_all(current_source_values)}\\n\"\n",
    "\n",
    "            result += (f\"The flow was found from: {flow.sources} -------> {flow.sink}\\n\")\n",
    "            if flow.icc_sink:\n",
    "                result +=(f\"Flow was found via ICC from {flow.icc_source} - {flow.icc_sink}\\n\")\n",
    "            if len(current_sink_values) > 0:\n",
    "                result +=(f\"We reconstructed for the sink connection: {parse_all(current_sink_values)}\\n\")\n",
    "\n",
    "            result += \"--------------------------------------------------------------\\n\"\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def print_flows_with_source_sink_connection(dataset: List[AnalyzedApp], only_if_sink_values:bool = False):\n",
    "    print(get_flows_with_source_sink_connection(dataset, only_if_sink_values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27eaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bl_run_config = \"/bl_config.xml\"\n",
    "icc_sinks = get_icc_sinks(path_bl_run_config)\n",
    "icc_sinks_methods = get_only_method_list(icc_sinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be23a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd53cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e77df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c91ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2819bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5292f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2660192",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d52339",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_local: List[FlowDroidRun] = parse_local_dataset(\"/iotflow/gp_2022\")\n",
    "general_bl: List[FlowDroidRun] = parse_bl_dataset(\"/iotflow/gp_2022\")\n",
    "general_general: List[FlowDroidRun] = parse_general_dataset(\"/iotflow/gp_2022\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a621a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0999d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mapping_file = \"/verified_dataset/result.json\"\n",
    "verfied_local: List[FlowDroidRun] = parse_verified_dataset_local(\"/iotflow/\",\n",
    "                                                                 mapping_file)\n",
    "verfied_bl: List[FlowDroidRun] = parse_verified_dataset_bl(\"/iotflow/\", mapping_file)\n",
    "verfied_general: List[FlowDroidRun] = parse_verified_dataset_general(\"/iotflow/\",\n",
    "                                                                     mapping_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca176ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_gp_local = analyze_dataset(general_local)\n",
    "\n",
    "analyzed_gp_local = get_all_source_sink_connection(analyzed_gp_local)\n",
    "filtered_gp_local = filter_java_sinks(analyzed_gp_local)\n",
    "filtered_gp_local_2 = filter_local_dataset(filtered_gp_local)\n",
    "\n",
    "filtered_gp_local_3 = filter_local_dataset(filtered_gp_local_2, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaeae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_gp_bl = analyze_dataset(general_bl)\n",
    "\n",
    "analyzed_gp_bl = get_all_source_sink_connection(analyzed_gp_bl)\n",
    "filtered_gp_bl = filter_java_sinks(analyzed_gp_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_gp_general = analyze_dataset(general_general)\n",
    "\n",
    "analyzed_gp_general = get_all_source_sink_connection(analyzed_gp_general)\n",
    "filtered_gp_general = filter_java_sinks(analyzed_gp_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f284b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ffbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_verified_local = analyze_dataset(verfied_local)\n",
    "\n",
    "analyzed_verified_local = get_all_source_sink_connection(analyzed_verified_local)\n",
    "filtered_verified_local = filter_java_sinks(analyzed_verified_local)\n",
    "filtered_verified_local_2 = filter_local_dataset(filtered_verified_local)\n",
    "\n",
    "filtered_verified_local_3 = filter_local_dataset(filtered_verified_local, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_verified_bl = analyze_dataset(verfied_bl)\n",
    "\n",
    "analyzed_verified_bl = get_all_source_sink_connection(analyzed_verified_bl)\n",
    "filtered_verified_bl = filter_java_sinks(analyzed_verified_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ab6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_verified_general = analyze_dataset(verfied_general)\n",
    "\n",
    "analyzed_verified_general = get_all_source_sink_connection(analyzed_verified_general)\n",
    "filtered_verified_general = filter_java_sinks(analyzed_verified_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(filtered_verified_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc881f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_general(filtered_verified_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(filtered_verified_local_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(filtered_verified_local_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcf7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flows_with_source_sink_connection(filtered_verified_local_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(filtered_gp_general)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flows_with_source_sink_connection(filtered_verified_bl, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flows_with_source_sink_connection(filtered_verified_local_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_flows, count_apps, flows_via_icc, flows_with_sink_values, apps_with_sink_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb588c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_row(bl, local, general):\n",
    "    if bl[0] > 0:\n",
    "        bl_icc = f\"{bl[2]} ({bl[2]/bl[0]*100:.2f}%)\"\n",
    "        bl_sink = f\"{bl[3]} ({bl[3]/bl[0]*100:.2f}%)\"\n",
    "    else:\n",
    "        bl_icc = 0\n",
    "        bl_sink = 0\n",
    "\n",
    "    if local[0] > 0:\n",
    "        local_icc = f\"{local[2]} ({local[2]/local[0]*100:.2f}%)\"\n",
    "        local_sink =f\"{local[3]} ({local[3]/local[0]*100:.2f}%)\"\n",
    "    else:\n",
    "        local_icc = 0\n",
    "        local_sink = 0\n",
    "\n",
    "    if general[0] > 0:\n",
    "        general_icc =f\"{general[2]} ({general[2]/general[0]*100:.2f}%)\"\n",
    "        general_sink = f\"{general[3]} ({general[3]/general[0]*100:.2f}%)\"\n",
    "    else:\n",
    "        general_icc = 0\n",
    "        general_sink = 0\n",
    "\n",
    "    return [ bl_icc, bl_sink,bl[0], bl[1], local_icc, local_sink,  local[0],local[1], general_icc, general_sink,general[0], general[1]]\n",
    "\n",
    "rows =[]\n",
    "rows.append(create_row(get_stats(filtered_verified_bl), get_stats(filtered_verified_local_2), get_stats(filtered_verified_general )))\n",
    "rows.append(create_row(get_stats(filtered_gp_bl), get_stats(filtered_gp_local_2), get_stats(filtered_gp_general) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flows = pd.DataFrame(rows, index=[\"IoT-VER\", \"GP-2022\"], columns=[ \"ICC\", \"Endpoint\",\"flows\", \"apps\",\"ICC\", \"Endpoint\",\"flows\", \"apps\", \"ICC\", \"Endpoint\", \"flows\",\"apps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94863c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_row(df, total, row_name):\n",
    "    result = []\n",
    "    for row in df.iterrows():\n",
    "        current_row = []\n",
    "        print(row[0])\n",
    "        for value in row[1].iteritems():\n",
    "            if row_name == row[0]:\n",
    "                if value[0] == \"apps\":\n",
    "                    current_row.append(f\"{value[1]} ({value[1]/total * 100:.2f}%)\")\n",
    "                else:\n",
    "                    current_row.append(value[1])\n",
    "            else:\n",
    "                current_row.append(value[1])\n",
    "        result.append(current_row)\n",
    "\n",
    "    return pd.DataFrame(result, index=df.index,columns =df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602275e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.loc[\"IoT-VER\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab08926",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in row.iteritems():\n",
    "    if item[0] == \"apps\":\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formatted = format_row(df_flows, 9889, \"IoT-VER\" )\n",
    "df_formatted = format_row(df_formatted, 947, \"GP-2022\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fa273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6522e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_formatted.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4691b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_icc_and_endpoints = df_formatted.drop(columns=['ICC', 'Endpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(without_icc_and_endpoints.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203816af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9279cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(get_flows_with_source_sink_connection(filtered_gp_bl, True), \"gp_bl.txt\")\n",
    "write_to_file(get_flows_with_source_sink_connection(filtered_gp_local_2, True), \"gp_local.txt\")\n",
    "write_to_file(get_flows_with_source_sink_connection(filtered_gp_general, True), \"gp_gen.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(get_flows_with_source_sink_connection(filtered_verified_bl, True), \"verified_bl.txt\")\n",
    "write_to_file(get_flows_with_source_sink_connection(filtered_verified_local_2, True), \"verified_local.txt\")\n",
    "write_to_file(get_flows_with_source_sink_connection(filtered_verified_general, True), \"verified_gen.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flows_with_source_sink_connection(filtered_verified_bl, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd99e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
